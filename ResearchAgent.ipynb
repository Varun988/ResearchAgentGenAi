{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "ETsfsi0DxThl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Importing libraries\n",
        "# from google.colab import drive\n",
        "# import sys\n",
        "# # Mount google drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# # Changing path dirctory\n",
        "# sys.path.append('/content/gdrive/My Drive/Colab Notebooks')\n"
      ],
      "metadata": {
        "id": "PkciG4ubNgFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os, sys\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# #create a path to save the module\n",
        "# nb_path = '/content/notebooks'\n",
        "# os.symlink('/content/gdrive/My Drive/Colab Notebooks', nb_path)\n",
        "# sys.path.insert(0, nb_path)"
      ],
      "metadata": {
        "id": "ylRwk1ftm_24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "27jSnp2gm_51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  pip install --target=$nb_path serpapi"
      ],
      "metadata": {
        "id": "YZC7eoPVm6xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5juE3myfF1a"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    input: str\n",
        "    chat_history: list[BaseMessage]\n",
        "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import serpapi\n",
        "serpapi_params = {\n",
        "    \"engine\": \"google\",\n",
        "    \"api_key\": \"\"\n",
        "    # os.getenv(\"SERPAPI_KEY\") or getpass(\"SerpAPI key: \")\n",
        "}\n",
        "\n",
        "search = serpapi.search({\n",
        "    **serpapi_params,\n",
        "    \"q\": \"coffee\"\n",
        "})\n",
        "\n",
        "# results = search.get_dict()[\"organic_results\"]\n",
        "results = search[\"organic_results\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "mJLrAuAYN8oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts = \"\\n---\\n\".join(\n",
        "    [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
        ")"
      ],
      "metadata": {
        "id": "igbFWMxTN8qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnh1XrxwN8s8",
        "outputId": "0eb0d0b3-f729-41c6-d666-83f5c72132e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coffee\n",
            "Coffee is a beverage brewed from roasted coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans, primarily due ...\n",
            "https://en.wikipedia.org/wiki/Coffee\n",
            "---\n",
            "Peet's Coffee | The Original Craft Coffee, Est. 1966\n",
            "Since 1966, Peet's Coffee has sourced and offered superior coffees and teas and adhering to strict high-quality and taste standards. Shop today.\n",
            "https://www.peets.com/\n",
            "---\n",
            "Blue Bottle Coffee | Fresh Roasted Specialty Coffee\n",
            "Blue Bottle Coffee is a specialty coffee roaster with cafes in LA, SF, NYC, & Japan. Shop our freshly roasted specialty coffee online & in-store.\n",
            "https://bluebottlecoffee.com/?srsltid=AfmBOoq0BsVydAbQTKYnQrLP3ahlpPCLpnh6og1ViQCli72SdJa47meV\n",
            "---\n",
            "Starbucks Coffee Company\n",
            "More than just great coffee. Explore the menu, sign up for StarbucksÂ® Rewards, manage your gift card and more.\n",
            "https://www.starbucks.com/\n",
            "---\n",
            "The Coffee Bean & Tea Leaf | CBTL\n",
            "We're passionate about delivering the best handcrafted products and take pride in the journey from seed to cup.\n",
            "https://coffeebean.com/\n",
            "---\n",
            "What is Coffee?\n",
            "Coffee traces its origin to a genus of plants known as Coffea. Within the genus there are over 500 genera and 6,000 species of tropical trees and shrubs.\n",
            "https://www.ncausa.org/About-Coffee/What-is-Coffee\n",
            "---\n",
            "Coffee health benefits: Diabetes, heart health, liver cancer, ...\n",
            "In some cases, coffee may be good for health, as it may offer benefits such as lowering the risk of type 2 diabetes and helping people lose weight.\n",
            "https://www.medicalnewstoday.com/articles/270202\n",
            "---\n",
            "BUT FIRST, COFFEE. - Los Angeles\n",
            "Since opening on Melrose Place in 2013, Alfred has made waves with its sleek decors, killer customer service, and innovative coffee and tea drinks.\n",
            "https://alfred.la/?srsltid=AfmBOoq179rXRSqJM0g3M6XLGfmcHJflZ40oNCoZOITGkFJNJmLFhhqC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool # Import the tool decorator from langchain.tools\n",
        "\n",
        "@tool(\"web_search\")\n",
        "def web_search(query: str):\n",
        "    \"\"\"Finds general knowledge information using Google search. Can also be used\n",
        "    to augment more 'general' knowledge to a previous specialist query.\"\"\"\n",
        "    search = serpapi.search({\n",
        "        **serpapi_params,\n",
        "        \"q\": query,\n",
        "        \"num\": 1\n",
        "    })\n",
        "    results = search[\"organic_results\"]\n",
        "    contexts = \"\\n---\\n\".join(\n",
        "        [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
        "    )\n",
        "    return contexts"
      ],
      "metadata": {
        "id": "SjxHzspcQx9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool(\"final_answer\")\n",
        "def final_answer(\n",
        "    introduction: str,\n",
        "    research_steps: str,\n",
        "    main_body: str,\n",
        "    conclusion: str,\n",
        "    sources: str\n",
        "):\n",
        "    \"\"\"Returns a natural language response to the user in the form of a research\n",
        "    report. There are several sections to this report, those are:\n",
        "    - `introduction`: a short paragraph introducing the user's question and the\n",
        "    topic we are researching.\n",
        "    - `research_steps`: a few bullet points explaining the steps that were taken\n",
        "    to research your report.\n",
        "    - `main_body`: this is where the bulk of high quality and concise\n",
        "    information that answers the user's question belongs. It is 3-4 paragraphs\n",
        "    long in length.\n",
        "    - `conclusion`: this is a short single paragraph conclusion providing a\n",
        "    concise but sophisticated view on what was found.\n",
        "    - `sources`: a bulletpoint list provided detailed sources for all information\n",
        "    referenced during the research process\n",
        "    \"\"\"\n",
        "    if type(research_steps) is list:\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    if type(sources) is list:\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "NI7t4joJa9c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "system_prompt = \"\"\"You are the oracle, the great AI decision maker.\n",
        "Given the user's query you must decide what to do with it based on the\n",
        "list of tools provided to you.\n",
        "\n",
        "If you see that a tool has been used (in the scratchpad) with a particular\n",
        "query, do NOT use that same tool with the same query again. Also, do NOT use\n",
        "any tool more than twice (ie, if the tool appears in the scratchpad twice, do\n",
        "not use it again).\n",
        "\n",
        "You should aim to collect information from a diverse range of sources before\n",
        "providing the answer to the user. Once you have collected plenty of information\n",
        "to answer the user's question (stored in the scratchpad) use the final_answer\n",
        "tool.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"assistant\", \"scratchpad: {scratchpad}\"),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "PKW2aDSNbnPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install langchain_groq"
      ],
      "metadata": {
        "id": "rUtjrxG6mFAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolCall, ToolMessage\n",
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key='',\n",
        "    # model_name=\"llama-3.1-70b-versatile\"\n",
        "    model=\"llama3-70b-8192\"\n",
        "\n",
        ")\n",
        "\n",
        "tools=[\n",
        "    # rag_search_filter,\n",
        "    # rag_search,\n",
        "    # fetch_arxiv,\n",
        "    web_search,\n",
        "    final_answer\n",
        "]\n",
        "\n",
        "# define a function to transform intermediate_steps from list\n",
        "# of AgentAction to scratchpad string\n",
        "def create_scratchpad(intermediate_steps: list[AgentAction]):\n",
        "    research_steps = []\n",
        "    for i, action in enumerate(intermediate_steps):\n",
        "         if action.log != \"TBD\":\n",
        "            # this was the ToolExecution\n",
        "            research_steps.append(\n",
        "                f\"Tool: {action.tool}, input: {action.tool_input}\\n\"\n",
        "                f\"Output: {action.log}\"\n",
        "            )\n",
        "    return \"\\n---\\n\".join(research_steps)\n",
        "\n",
        "oracle = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"scratchpad\": lambda x: create_scratchpad(\n",
        "            intermediate_steps=x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice=\"auto\")\n",
        ")"
      ],
      "metadata": {
        "id": "UZ4YcIcyfExS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"input\": \"tell me something about planets\",\n",
        "    \"chat_history\": [],\n",
        "    \"intermediate_steps\": [],\n",
        "}\n",
        "out = oracle.invoke(inputs)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUiJqm0YonGe",
        "outputId": "dcba2045-5308-4cc2-9bf6-0f084ac4541d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jas9', 'function': {'arguments': '{\"query\":\"tell me something about planets\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 1433, 'total_tokens': 1470, 'completion_time': 0.115689417, 'prompt_time': 0.111686309, 'queue_time': 0.018927631000000014, 'total_time': 0.227375726}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-01ee1602-4749-40e4-b07e-dc7d1e285eee-0', tool_calls=[{'name': 'web_search', 'args': {'query': 'tell me something about planets'}, 'id': 'call_jas9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1433, 'output_tokens': 37, 'total_tokens': 1470})"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.tool_calls[0][\"name\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "r-fj08dzonL7",
        "outputId": "e885e5bd-165a-4b77-fdf1-b86e8d71a9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'web_search'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.tool_calls[0][\"args\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22ZU1LeupgHF",
        "outputId": "d7285029-378f-4a2a-f300-2f284976d4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'tell me something about planets'}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_oracle(state):\n",
        "    print(f\"intermediate_steps: {state['intermediate_steps']}\")\n",
        "    out = oracle.invoke(state)\n",
        "    # Check if tool_calls is not empty before accessing the first element\n",
        "    if out.tool_calls:\n",
        "        tool_name = out.tool_calls[0][\"name\"]\n",
        "        tool_args = out.tool_calls[0][\"args\"]\n",
        "        action_out = AgentAction(\n",
        "            tool=tool_name,\n",
        "            tool_input=tool_args,\n",
        "            # log=str(out)\n",
        "            log=\"TBD\"\n",
        "        )\n",
        "        return {\"intermediate_steps\": [action_out]}\n",
        "    else:\n",
        "        # Handle the case where no tool is called (e.g., return a default value or raise an exception)\n",
        "        return {\"intermediate_steps\": []} # Or handle it differently based on your needs\n",
        "\n",
        "# def run_oracle(state: list):\n",
        "#     print(\"run_oracle\")\n",
        "#     print(f\"intermediate_steps: {state['intermediate_steps']}\")\n",
        "#     out = oracle.invoke(state)\n",
        "#     tool_name = out.tool_calls[0][\"name\"]\n",
        "#     tool_args = out.tool_calls[0][\"args\"]\n",
        "#     action_out = AgentAction(\n",
        "#         tool=tool_name,\n",
        "#         tool_input=tool_args,\n",
        "#         log=\"TBD\"\n",
        "#     )\n",
        "#     return {\n",
        "#         \"intermediate_steps\": [action_out]\n",
        "#     }\n",
        "\n",
        "\n",
        "\n",
        "def router(state: list):\n",
        "    # return the tool name to use\n",
        "    if isinstance(state[\"intermediate_steps\"], list):\n",
        "        return state[\"intermediate_steps\"][-1].tool\n",
        "    else:\n",
        "        # if we output bad format go to final answer\n",
        "        print(\"Router invalid format\")\n",
        "        return \"final_answer\""
      ],
      "metadata": {
        "id": "YXEelQKWpiT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_str_to_func = {\n",
        "    # \"rag_search_filter\": rag_search_filter,\n",
        "    # \"rag_search\": rag_search,\n",
        "    # \"fetch_arxiv\": fetch_arxiv,\n",
        "    \"web_search\": web_search,\n",
        "    \"final_answer\": final_answer\n",
        "}\n",
        "\n",
        "def run_tool(state: list):\n",
        "    # use this as helper function so we repeat less code\n",
        "    tool_name = state[\"intermediate_steps\"][-1].tool\n",
        "    tool_args = state[\"intermediate_steps\"][-1].tool_input\n",
        "    print(f\"{tool_name}.invoke(input={tool_args})\")\n",
        "    # run tool\n",
        "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log=str(out)\n",
        "    )\n",
        "    return {\"intermediate_steps\": [action_out]}"
      ],
      "metadata": {
        "id": "ZeIPtA3TqiIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"oracle\", run_oracle)\n",
        "# graph.add_node(\"rag_search_filter\", run_tool)\n",
        "# graph.add_node(\"rag_search\", run_tool)\n",
        "# graph.add_node(\"fetch_arxiv\", run_tool)\n",
        "graph.add_node(\"web_search\", run_tool)\n",
        "graph.add_node(\"final_answer\", run_tool)\n",
        "\n",
        "graph.set_entry_point(\"oracle\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    source=\"oracle\",  # where in graph to start\n",
        "    path=router,  # function to determine which node is called\n",
        ")\n",
        "\n",
        "# create edges from each tool back to the oracle\n",
        "for tool_obj in tools:\n",
        "    if tool_obj.name != \"final_answer\":\n",
        "        graph.add_edge(tool_obj.name, \"oracle\")\n",
        "\n",
        "# if anything goes to final answer, it must then move to END\n",
        "graph.add_edge(\"final_answer\", END)\n",
        "\n",
        "runnable = graph.compile()"
      ],
      "metadata": {
        "id": "8DLJVUhgqzGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import Image\n",
        "\n",
        "# Image(runnable.get_graph().draw_png())\n",
        "\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        runnable.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "gMBxRz0irT9A",
        "outputId": "d75808cf-077c-43ae-a909-80799ee9267d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VADOMNz0ram4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"tell me something about aliens\",\n",
        "    \"chat_history\": [],\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "bzsBVeSvscV_",
        "outputId": "09fdac54-627d-484c-cd1c-a36346e4e8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intermediate_steps: []\n",
            "web_search.invoke(input={'query': 'aliens'})\n",
            "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)')]\n",
            "web_search.invoke(input={'query': 'aliens'})\n",
            "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)')]\n",
            "web_search.invoke(input={'query': 'aliens'})\n",
            "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)')]\n",
            "web_search.invoke(input={'query': 'aliens'})\n",
            "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)')]\n",
            "web_search.invoke(input={'query': 'aliens'})\n",
            "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)')]\n",
            "web_search.invoke(input={'query': 'aliens'})\n",
            "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)')]\n",
            "web_search.invoke(input={'query': 'aliens'})\n",
            "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)'), AgentAction(tool='web_search', tool_input={'query': 'aliens'}, log='Aliens (film)\\nAliens is a 1986 science fiction action film written and directed by James Cameron. It is the sequel to the 1979 science fiction horror film Alien\\nhttps://en.wikipedia.org/wiki/Aliens_(film)')]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/content/notebooks/groq/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-50dc4914ec16>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m out = runnable.invoke({\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"tell me something about aliens\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"chat_history\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n",
            "\u001b[0;32m/content/notebooks/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   1552\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1288\u001b[0m                     \u001b[0mmanager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m                 ):\n\u001b[0;32m-> 1290\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1291\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mrun_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m# if successful, end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-04322453a076>\u001b[0m in \u001b[0;36mrun_oracle\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_oracle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"intermediate_steps: {state['intermediate_steps']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Check if tool_calls is not empty before accessing the first element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5341\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5343\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5344\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m         return cast(\n\u001b[1;32m    283\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    783\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m         flattened_outputs = [\n\u001b[1;32m    643\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 results.append(\n\u001b[0;32m--> 631\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    632\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    854\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 )\n",
            "\u001b[0;32m/content/notebooks/langchain_groq/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         }\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/groq/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    285\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m--> 287\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0;34m\"/openai/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/content/notebooks/groq/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         )\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     def patch(\n",
            "\u001b[0;32m/content/notebooks/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 936\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    937\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/groq/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1025\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/notebooks/groq/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0;31m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;31m# different thread if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         return self._request(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_report(output: dict):\n",
        "    research_steps = output[\"research_steps\"]\n",
        "    if type(research_steps) is list:\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    sources = output[\"sources\"]\n",
        "    if type(sources) is list:\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "    return f\"\"\"\n",
        "INTRODUCTION\n",
        "------------\n",
        "{output[\"introduction\"]}\n",
        "\n",
        "RESEARCH STEPS\n",
        "--------------\n",
        "{research_steps}\n",
        "\n",
        "REPORT\n",
        "------\n",
        "{output[\"main_body\"]}\n",
        "\n",
        "CONCLUSION\n",
        "----------\n",
        "{output[\"conclusion\"]}\n",
        "\n",
        "SOURCES\n",
        "-------\n",
        "{sources}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hRlQMBzVvgtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ],
      "metadata": {
        "id": "UUfcGSW6w6RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the content of the AIMessage using the 'content' attribute\n",
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].content.tool_input\n",
        "))"
      ],
      "metadata": {
        "id": "fc88zSTE7IoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjPaU--m7TT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
